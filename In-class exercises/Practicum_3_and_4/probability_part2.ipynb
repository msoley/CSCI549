{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import chi2\n",
    "from scipy.special import binom\n",
    "import pylab as p\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Verify that if $X_i\\sim N(\\mu,\\sigma^2)$ then the distribution of the sample mean $\\overline{X}_n=\\frac{1}{n}\\sum_{i=1}^n X_i$ is $N(\\mu,\\sigma^2/n)$\n",
    "\n",
    "**Solution:** sample $m$ sequences of $n$ elements from $N(\\mu,\\sigma^2)$, compute $m$ sample means, compute the histogram and plot it along with $N(\\mu,\\sigma^2/n)$\n",
    "\n",
    "Note that the distribution of the sample mean is much narrower. In fact how narrow it is depends on the size $n$ of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_and_histo(f,r=[], label=\"\",c='r-'):\n",
    "    x = np.linspace(f.ppf(0.001), f.ppf(0.999), 100)\n",
    "    ax.plot(x, f.pdf(x), c, lw=1, alpha=0.6, label=label)\n",
    "    if len(r) > 0:\n",
    "        ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    \n",
    "mu = 5\n",
    "sigma = 4\n",
    "\n",
    "n = 10     # number of sample means\n",
    "m = 1000   # number of points used in each sample mean\n",
    "\n",
    "f = norm\n",
    "r = f.rvs(size=(m,n))\n",
    "r = sigma * r + mu\n",
    "          \n",
    "sample_means = np.mean(r,axis=1)\n",
    "\n",
    "f = norm(loc=mu,scale=sigma/np.sqrt(n))\n",
    "label = \"means ~ N({},{})\".format(mu,sigma*sigma/n)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "plot_curve_and_histo(f,sample_means,label)\n",
    "\n",
    "label_original = \"X ~ N({},{})\".format(mu,sigma*sigma)\n",
    "plot_curve_and_histo(norm(loc=mu,scale=sigma),[],label_original, 'b-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** draw $\\Phi(x)=P(X\\leq x)$ for $X\\sim N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_and_histo(f,r=[], label=\"\",c='r-'):\n",
    "    x = np.linspace(f.ppf(0.001), f.ppf(0.999), 100)\n",
    "    ax.plot(x, f.cdf(x), c, lw=1, alpha=0.6, label=label)\n",
    "    if len(r) > 0:\n",
    "        ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    \n",
    "f = norm()\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plot_curve_and_histo(f,[],\"Phi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universal Transformation of Probability**\n",
    "\n",
    "Let $X$ be an arbitrary RV. Then $F_X(x)=P(X\\leq x)$ is a monotone nondecreasing function (invertible). Since $X$ is a RV then $Y=F_X(X)$ is also a RV.\n",
    "\n",
    "What is the distribution of $Y$?\n",
    "\n",
    "$P(Y\\leq y)=P(F_X(X)\\leq y)=P(X\\leq F_X^{-1}(y))=F_X(F_X^{-1}(y))=y$\n",
    "\n",
    "This is the cdf of the uniform density on $[0,1]$ (we can find that through differentiation of $P(Y\\leq y)$ with respect to $y$).\n",
    "\n",
    "Thus, $Y\\sim U[0,1]$: uniform on interval $[0,1]$\n",
    "\n",
    "**Problem:** Sample from $N(0,1)$ using a random number generator that samples uniformly at random from interval $[0,1]$\n",
    "\n",
    "**Solution:** Use the Universal transformation of probability: sample $X\\sim U(0,1)$. Then return $\\Phi^{-1}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_and_histo(f,r=[], label=\"\",c='r-'):\n",
    "    x = np.linspace(f.ppf(0.001), f.ppf(0.999), 100)\n",
    "    ax.plot(x, f.pdf(x), c, lw=1, alpha=0.6, label=label)\n",
    "    if len(r) > 0:\n",
    "        ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "\n",
    "n = 1000\n",
    "mu = 2\n",
    "sigma = 5\n",
    "\n",
    "# Sample n points x_1, x_2, \\ldots, x_n unformly at random from [0,1]\n",
    "x = np.random.random(n)\n",
    "\n",
    "# Find inverse images wrt Phi\n",
    "f = norm(loc=mu,scale=sigma)\n",
    "y = f.ppf(x)\n",
    "\n",
    "# plot gaussian N(mu,sigma^2) and histogram of y\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plot_curve_and_histo(f,y,\"N({},{})\".format(mu,sigma**2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Central Limit Theorem**\n",
    "\n",
    "Recall from the lectures that given a sequence of iid RVs with mean $\\mu$ and variance $\\sigma^2$ it holds that\n",
    "\n",
    "$\\lim_{n\\rightarrow\\infty} \\frac{1}{n}\\sum_{i=1}^n X_i \\sim N(\\mu,\\sigma^2/n)$\n",
    "\n",
    "**Problem:** verify experimentally how the CLT performs on the sample mean of uniform RVs for $n=10$\n",
    "\n",
    "**Solution:** observe that if $X\\sim U[0,1]$ then $E[X]=1/2$ and $var[X]=E[X^2]-E[X]^2=1/3-1/4=1/12$. Then sample $m$ sequences of $n$ trials and draw the histogram of the corresponding sample means along with the graph of $N(1/2,1/(n*144))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve_and_histo(f,r=[], label=\"\",c='r-'):\n",
    "    x = np.linspace(f.ppf(0.001), f.ppf(0.999), 100)\n",
    "    ax.plot(x, f.pdf(x), c, lw=1, alpha=0.6, label=label)\n",
    "    if len(r) > 0:\n",
    "        ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "    \n",
    "\n",
    "n = 10\n",
    "m = 1000\n",
    "\n",
    "mu = 1/2\n",
    "sigma = np.sqrt(1/12)/np.sqrt(n)\n",
    "\n",
    "f = norm(loc=mu,scale=sigma)\n",
    "\n",
    "(mean_f, variance_f) = f.stats('mv')\n",
    "print(\"mean = {} variance = {}\".format(mean_f,variance_f))\n",
    "      \n",
    "r = np.random.random((m,n))\n",
    "sample_means = np.mean(r,axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "label = \"X ~ N({},{:0.3f})\".format(mu,sigma*sigma)\n",
    "plot_curve_and_histo(f,sample_means,label)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Correlation and Dependence**\n",
    "\n",
    "The Pearson correlation coefficient between two RVs $X$ and $Y$ is defined as\n",
    "\n",
    "$r=\\frac{E[(X-\\mu_X)(Y-\\mu_Y)]}{E[(X-\\mu_X)^2]^{1/2}E[(Y-\\mu_Y)^2]^{1/2}}$\n",
    "\n",
    "**Problem:** Let $X\\sim N(0,1)$ and $Y=\\alpha X$, estimate $corr(X,Y)$\n",
    "\n",
    "**Solution:** replace expectations with sample means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x,y):\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    return np.sum(x * y) / (np.sqrt(np.sum(x*x))*np.sqrt(np.sum(y*y)))\n",
    "    \n",
    "n = 1000\n",
    "alpha = 10\n",
    "\n",
    "x = norm.rvs(size=n)\n",
    "y = alpha * x\n",
    "\n",
    "# compute correlation coefficient\n",
    "r = corr(x,y)\n",
    "print(\"corr(X,Y) = {:0.2f}\".format(r))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, y, 'r-', lw=1, alpha=0.6, label=\"y={:0.0f}*x, x~N(0,1)\".format(alpha))\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Let $X\\sim N(0,1)$ and $Y=X^2$, estimate $corr(X,Y)$\n",
    "\n",
    "**Solution:** replace expectations with sample means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x,y):\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    return np.sum(x * y) / (np.sqrt(np.sum(x*x))*np.sqrt(np.sum(y*y)))\n",
    "    \n",
    "n = 1000\n",
    "alpha = 10\n",
    "\n",
    "x = norm.rvs(size=n)\n",
    "y = x ** 2\n",
    "\n",
    "r = corr(x,y)\n",
    "print(\"corr(X,Y) = {:0.3f}\".format(r))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, y, 'r-', lw=1, alpha=0.6, label=\"corr(X,X^2)\")\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\chi^2$** distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [1,2,3,4,5,6,7]\n",
    "c = ['r-','b-','g-','y-','c-','m-','k-']\n",
    "p = zip(df,c)\n",
    "\n",
    "x = np.arange(0, 8, 0.001)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for (k,c) in p:\n",
    "    if k == 1:\n",
    "        xx = x[100:]\n",
    "    else:\n",
    "        xx = x\n",
    "    ax.plot(xx, chi2.pdf(xx,df=k), c, lw=1, alpha=0.6, label = \"k={}\".format(k))\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Given a sequence of independent standard normal RVs $X_1,X_2,\\ldots,X_n$ the sum of their squares is distributed according to a $\\chi^2_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000\n",
    "n = 7\n",
    "k = n\n",
    "x = np.arange(0, 17, 0.001)\n",
    "\n",
    "y = norm.rvs(size=(m,n))\n",
    "y = y ** 2\n",
    "\n",
    "s = np.sum(y,axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, chi2.pdf(x,df=k), c, lw=1, alpha=0.6, label = \"chi^2({})\".format(k))\n",
    "ax.hist(s, density=True, histtype='stepfilled', alpha=0.2)\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Given a sequence of $n$ independent normal RVs, with $X_i\\sim N(\\mu,1)$ show experimentally that the sum of the squares of the centered variables is distributed according to a  $\\chi^2(n-1)$\n",
    "\n",
    "Observe that, for $n=2$, $X_1-(X_1+X_2)/2=-(X_2+(X_1+X_2)/2)$. Thus, the two centered variables are not indepedent. This explains why the numeber of degrees of freedom decreases by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10000\n",
    "n = 7\n",
    "k = n-1\n",
    "mu = 2\n",
    "sigma = 1\n",
    "\n",
    "x = np.arange(0, 17, 0.001)\n",
    "\n",
    "y = norm.rvs(size=(m,n), loc=mu, scale=sigma)\n",
    "y = y - np.mean(y,axis=1)[np.newaxis].transpose()\n",
    "y = y ** 2\n",
    "\n",
    "s = np.sum(y,axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, chi2.pdf(x,df=k), c, lw=1, alpha=0.6, label = \"chi^2({})\".format(k))\n",
    "ax.hist(s, density=True, histtype='stepfilled', alpha=0.2)\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**t-distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = [1,2,3,4,5,6,7]\n",
    "c = ['r-','b-','g-','y-','c-','m-','k']\n",
    "p = zip(df,c)\n",
    "\n",
    "x = np.arange(-5, 5, 0.001)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for (k,c) in p:\n",
    "    ax.plot(x, t.pdf(x,df=k), c, lw=1, alpha=0.6, label = \"k={}\".format(k))\n",
    "    ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Significance Tests**\n",
    "\n",
    "Consider a sequence of samples $X_1,X_2,\\ldots,X_n$ with $X_i\\sim N(5,4)$.\n",
    "\n",
    "Assume that $\\sigma^2=4$ and run the following test at 95% significance level with $n=10$:\n",
    "\n",
    "$H_0$: $\\mu=3.8$\n",
    "\n",
    "$H_1$: $\\mu>3.8$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "alpha = 0.05\n",
    "mu = 5\n",
    "mu_0 = 3.8\n",
    "sigma_sq = 4\n",
    "sigma = np.sqrt(sigma_sq)\n",
    "\n",
    "def z_score(x,mu,s):\n",
    "    sample_mean = sum(x)/len(x)\n",
    "    return (sample_mean - mu)/(s/np.sqrt(len(x)))\n",
    "\n",
    "# sample data\n",
    "x = norm.rvs(size = n, loc=mu, scale = sigma)\n",
    "\n",
    "z = z_score(x,mu_0,sigma)\n",
    "\n",
    "p_value = 1-norm.cdf(z)\n",
    "\n",
    "print(p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject H0\")\n",
    "else:\n",
    "    print(\"Fail to Reject H0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following Binary Classification Problem\n",
    "\n",
    "**Input:** sequence $x_1,x_2,\\ldots,x_n$ of real numbers sampled iid according to a Normal RV $X\\sim N(\\mu_1,\\sigma_1^2)$\n",
    "\n",
    "**Output:** H0 or H1, where\n",
    "\n",
    "$H_0$: $\\mu=\\mu_0$, $\\sigma=\\sigma_1$\n",
    "\n",
    "$H_1$: $\\mu=\\mu_1$, $\\sigma=\\sigma_1$\n",
    "\n",
    "**Problem:** Estimate the *receiver operating characteristic curve* (ROC) curve of the maximum likelihood classifier using synthetic testing (labeled) data generated according to H0 and H1\n",
    "\n",
    "Observe the analogy with Neyman-Pearson Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "# True model\n",
    "mu = 1.1\n",
    "#mu = 1.5\n",
    "sigma_sq = 1\n",
    "sigma = np.sqrt(sigma_sq)\n",
    "\n",
    "# H0 model\n",
    "mu_0 = 1\n",
    "sigma_0 = sigma\n",
    "\n",
    "# H1 model is the right model\n",
    "mu_1 = mu\n",
    "sigma_1 = sigma\n",
    "\n",
    "# false positive and false negatives\n",
    "fpr_list = []\n",
    "fnr_list = []\n",
    "tpr_list = []\n",
    "tnr_list = []\n",
    "\n",
    "m = 1000\n",
    "\n",
    "deltas = np.linspace(0.01,19.99,100)\n",
    "\n",
    "# build synthetic testing data\n",
    "\n",
    "# sample from correct distribution\n",
    "x_1 = norm.rvs(size = (m,n), loc=mu, scale = sigma)\n",
    "\n",
    "# sample from wrong distribution\n",
    "x_0 = norm.rvs(size = (m,n), loc=mu_0, scale = sigma_0)\n",
    "\n",
    "# Build table of labeled samples\n",
    "x = np.r_[x_0,x_1]\n",
    "y = np.zeros(2*m)\n",
    "y[m:]=1\n",
    "\n",
    "for i in range(len(deltas)):\n",
    "    \n",
    "    delta = deltas[i]\n",
    "    \n",
    "    # computes log likelihoods of each sample given H0 and then given H1\n",
    "    log_likelihood0 = np.sum(norm.logpdf(x,loc=mu_0,scale=sigma_0), axis = 1)\n",
    "    log_likelihood1 = np.sum(norm.logpdf(x,loc=mu_1,scale=sigma_1), axis = 1)\n",
    "    result = log_likelihood1 >= math.log(1/delta) + log_likelihood0\n",
    "    \n",
    "    # measure error rates\n",
    "    \n",
    "    # True positive rate\n",
    "    tpr = sum((result == 1) & (y == 1))/sum(y == 1)\n",
    "    \n",
    "    # True negative rate\n",
    "    tnr = sum((result == 0) & (y == 0))/sum(y == 0)\n",
    "    \n",
    "    # False positive rate: P(H_1 accepted |H_0 was correct) = P( Type I error )\n",
    "    fpr = 1-tnr\n",
    "    \n",
    "    # False negative rate P(H_0 accepted | H_0 was false) = P( Type II error)\n",
    "    fnr = 1-tpr\n",
    "    \n",
    "    fpr_list.append(fpr)\n",
    "    fnr_list.append(fnr)\n",
    "    tpr_list.append(tpr)\n",
    "    tnr_list.append(tnr)\n",
    "\n",
    "# plot fp vs fn\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(fpr_list,tpr_list, 'r-', lw=1, alpha=0.6, label='ROC Curve')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, 1)\n",
    "#ax.annotate('ROC', xy=(0.9, 0.9))\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Simulate the hypothetical experimental study about the promotions approached with a nonparametric test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def partition(list_in,n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]\n",
    "\n",
    "# create deck card\n",
    "n_p = ['NP']*35\n",
    "p = ['P']*13\n",
    "tot = n_p + p\n",
    "\n",
    "# drawing simulation\n",
    "nsim = 10000\n",
    "diff_prom = []\n",
    "\n",
    "for i in np.arange(1,nsim,1):\n",
    "    men, women = partition(tot, 2)\n",
    "    men_p = men.count('P')/24\n",
    "    women_p = women.count('P')/24\n",
    "    diff_prom.append(men_p-women_p)\n",
    "    \n",
    "# Make the plot\n",
    "plt.hist(diff_prom)\n",
    "\n",
    "# p-value\n",
    "p_value = np.size(np.where(np.array(diff_prom)>0.3))/np.size(diff_prom)\n",
    "\n",
    "print(\"p-value({}) = {:0.5f}\".format(0.3,p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
