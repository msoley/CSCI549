{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZjf5P-99MEv"
      },
      "source": [
        "### Gradient Descent Algorithm for Linear Regression (10 points)\n",
        "\n",
        "The gradient descent algorithm is a powerful optimization technique used to iteratively refine model parameters for a better fit. In the context of linear regression, it aims to find optimal values of the slope $ m $ and intercept $ c $ that minimize the mean squared error between the predicted and actual values.\n",
        "\n",
        "The steps for each iteration (or epoch) are:\n",
        "\n",
        "1. **Prediction:**\n",
        "   Use the current values of $ m $ and $ c $ to calculate the predicted values:\n",
        "   $ y_{\\text{pred}} = w \\cdot x + b $\n",
        "\n",
        "2. **Compute Gradients:**\n",
        "   Determine the gradient of the loss with respect to each parameter:\n",
        "   - Gradient with respect to the slope $ m $:\n",
        "$$\n",
        "D_w = \\frac{-2}{n} \\sum (x \\cdot (y_{\\text{noisy}} - y_{\\text{pred}}))\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "   - Gradient with respect to the intercept $ c $:\n",
        "$$\n",
        "D_b = \\frac{-2}{n} \\sum (y_{\\text{noisy}} - y_{\\text{pred}})\n",
        "$$\n",
        "\n",
        "3. **Update Parameters:**\n",
        "   Adjust $ w $ and $ b $ based on the gradients and the learning rate $ \\alpha $:\n",
        "   $$ w = w - \\alpha \\cdot D_w $$\n",
        "   $$ b = b - \\alpha \\cdot D_b $$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "x = np.linspace(0, 10, 100)\n",
        "\n",
        "# Noisy Linear Data generation\n",
        "y_linear_noisy = 3*x + 2 + np.random.randn(100)*5\n",
        "\n",
        "# Initial values for m (slope) and c (intercept)\n",
        "w, b = 0, 0  # Model parameters\n",
        "learning_rate = 0.01\n",
        "epochs = 15  # Limit to 15 epochs\n",
        "\n",
        "# Lists to save the plots at each epoch for visualization\n",
        "lines = []\n",
        "\n",
        "# Gradient Descent\n",
        "for epoch in range(epochs):\n",
        "    # Make predictions, watch formula listed above to implement\n",
        "    y_pred = # Your code here\n",
        "\n",
        "    # Calculate gradients\n",
        "    D_w = (-2/len(x)) * sum(x * (y_linear_noisy - y_pred))\n",
        "    D_b = # Your code here\n",
        "\n",
        "    # Update parameters, watch formulas listed above to implement\n",
        "    w = # Your code here\n",
        "    b = # Your code here\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.scatter(x, y_linear_noisy, c='blue', label='Noisy Linear Data')\n",
        "    plt.plot(x, w*x+b, '-r', label=f'Epoch {epoch+1}')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.title(f'Gradient Descent Epoch {epoch+1}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    filename = f'epoch_{epoch}.png'\n",
        "    plt.savefig(filename)\n",
        "    lines.append(filename)\n",
        "    plt.close()\n",
        "\n",
        "# Create gif with slowed down duration and infinite loop\n",
        "with imageio.get_writer('gradient_descent.gif', mode='I', duration=700, loop = 0) as writer:  # duration is in seconds per frame\n",
        "    for filename in lines:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "# Cleanup the individual frames\n",
        "for filename in lines:\n",
        "    os.remove(filename)\n",
        "\n",
        "# Display the optimized parameters and the gif\n",
        "print(f\"Optimized Parameters: Slope (m) = {w}, Intercept (c) = {b}\")\n",
        "\n",
        "# Display gif in Jupyter notebook\n",
        "from IPython.display import Image\n",
        "Image(filename=\"gradient_descent.gif\")  # loop=0 makes it loop indefinitely\n"
      ],
      "metadata": {
        "id": "A3pQ2-KaEo4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXZLpaBY9MFA"
      },
      "source": [
        "### Linear regression using sklearn (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJMNacqv9MFB"
      },
      "source": [
        "Load the dataset and perform basic data exploration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3uLLt2g9MFC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "california_housing = fetch_california_housing(as_frame=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "df['MedHouseVal'] = california_housing.target\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FovzYyAu9MFD"
      },
      "source": [
        "Split the data into training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V85hXIiB9MFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('MedHouseVal', axis=1)\n",
        "y = df['MedHouseVal']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm_bUcqs9MFE"
      },
      "source": [
        "Fit a linear regression model to the training data and evaluate its performance on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBq8OPHM9MFF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "# set random seed\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create a model object\n",
        "reg = #Your code here\n",
        "model = make_pipeline(StandardScaler(),\n",
        "                      reg\n",
        "                      )\n",
        "# In case of any difficulties check: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor\n",
        "\n",
        "# Fit the model to the training data\n",
        "# Your code here\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = # Your code here\n",
        "\n",
        "# Calculate and display the mean squared error between the actual and predicted values on test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "\n",
        "# Plot the actual vs predicted values\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.title(\"Actual Prices vs Predicted Prices\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKIctCco9MFH"
      },
      "source": [
        "Tip: SGDRegressor has fit and predict methods\n",
        "\n",
        "(10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he50BB4q9MFI"
      },
      "source": [
        "### Changing hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM3ViswE9MFJ"
      },
      "source": [
        "What heppends with accurancy if you change  max_iter to 3? Modify and place code in the cell below.\n",
        "\n",
        "\n",
        "How can you explain this behavior? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChT4s9BM9MFK"
      },
      "outputs": [],
      "source": [
        "# Place modified code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xKGk9Vp9MFK"
      },
      "source": [
        "### Regularization Parameter Search for Ridge Regression (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxHLbhTE9MFK"
      },
      "source": [
        "\n",
        "\n",
        "Manually search for the best regularization parameter alpha in Ridge regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFqw4F8f9MFL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize and fit the scaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLTLAmf49MFL"
      },
      "source": [
        "Find optimal value of alpha for Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg9XOlf19MFL"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# List of alphas (regularization parameters) to test\n",
        "alphas = [1e-5, 1e-3, 1e-2, 100, 500, 1000, 10000]\n",
        "\n",
        "\n",
        "alpha = # Your code here, you can chose any value from the list above\n",
        "\n",
        "ridge = Ridge(alpha=alpha)\n",
        "ridge.fit(X_train_scaled, y_train)\n",
        "# In case of any difficulties check: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
        "\n",
        "# Predict on the validation data\n",
        "y_pred = # Your code here\n",
        "\n",
        "# Calculate the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Alpha Value: {alpha}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "NEoqDjFU_03l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZHrnP659MFM"
      },
      "source": [
        "What happends when alpha is too high or too low?\n",
        "\n",
        "Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqa7C0Ds9MFM"
      },
      "source": [
        "## Classification with the Iris Dataset Using Logistic Regression (8 points)\n",
        "Load the dataset and perform basic data exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWklXw0M9MFM"
      },
      "source": [
        "Split the data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caH5eV5b9MFM"
      },
      "source": [
        "Train a Logistic Regression classifier and evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsAaN5f19MFM"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Visualize the dataset using a pair plot\n",
        "sns.pairplot(iris, hue=\"species\")\n",
        "plt.show()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = iris.drop(\"species\", axis=1)\n",
        "y = iris[\"species\"]\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-sk8MlY9MFW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a logistic regression model with OvR multi-class strategy, peek suitable value for max_iter\n",
        "clf = # Your code here\n",
        "\n",
        "# In case of any difficulties check: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
        "# Train the model\n",
        "# Your code here\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predict the species for the test set\n",
        "y_pred = # Your code here\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Display a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# For simplicity, let's visualize using only the first two features (sepal length and sepal width)\n",
        "X_train_2d = X_train[:, :2]\n",
        "\n",
        "# Train the model again on the 2D data\n",
        "clf.fit(X_train_2d, y_train)\n",
        "\n",
        "# Plot the decision boundaries\n",
        "x_min, x_max = X_train_2d[:, 0].min() - 1, X_train_2d[:, 0].max() + 1\n",
        "y_min, y_max = X_train_2d[:, 1].min() - 1, X_train_2d[:, 1].max() + 1\n",
        "\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                     np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode labels into numbers\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Train the classifier again on the 2D data\n",
        "clf.fit(X_train_2d, y_train_encoded)\n",
        "\n",
        "# Predict\n",
        "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# No need to decode since we're just plotting the boundaries\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "sns.scatterplot(x=X_train_2d[:, 0], y=X_train_2d[:, 1], hue=label_encoder.transform(y_train))\n",
        "plt.title('Decision Boundaries with Sepal Length and Sepal Width')\n",
        "plt.xlabel('Sepal Length (Standardized)')\n",
        "plt.ylabel('Sepal Width (Standardized)', )\n",
        "plt.legend(title='Legend', loc='best', labels=['setosa', 'versicolor', 'virginica'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWpaxCsD9MFY"
      },
      "source": [
        "# Understanding Overfitting and Underfitting (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXa15CD69MFa"
      },
      "source": [
        "One of the most important step in evaluating a machine learning model is to undersand whether the model overfits or underfits the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiq2VzAx9MFa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# set seed\n",
        "np.random.seed(132)\n",
        "\n",
        "\n",
        "def true_fun(X):\n",
        "    return np.cos(2 * np.pi * X)\n",
        "\n",
        "n_samples = 50\n",
        "X = np.sort(np.random.rand(n_samples))\n",
        "y = true_fun(X) + np.random.randn(n_samples) * 0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JDj6g2_9MFb"
      },
      "source": [
        "The aim is to try to fit a polynomial function of degree n to the data. n should be chosen as to not overfit or underfit the underlying data. This is often a trial-and-error process, using cross-validation and visualization to estimate the \"best\" fit to the trainig data.\n",
        "\n",
        "The first step is to fit the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o7bkuFH9MFb"
      },
      "outputs": [],
      "source": [
        "\n",
        "degrees = int(input(\"Please Enter The Degree of Polynomial Between 1-20:\"))\n",
        "\n",
        "polynomial_features = PolynomialFeatures(degree=degrees,\n",
        "                                          include_bias=False)\n",
        "linear_regression = LinearRegression()\n",
        "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                      (\"linear_regression\", linear_regression)])\n",
        "pipeline.fit(X[:, np.newaxis], y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKFmUW7i9MFd"
      },
      "source": [
        "Then to evaluate the model using cross-validation and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHViW2ID9MFd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n",
        "                          scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "X_test = np.linspace(0, 1, 100)\n",
        "plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
        "plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
        "plt.scatter(X, y, edgecolor='r', s=20, label=\"Samples\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.xlim((0, 1))\n",
        "plt.ylim((-2, 2))\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
        "    degrees, -scores.mean(), scores.std()))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_Kp9lcj9MFe"
      },
      "source": [
        "Optimal degree in terms of MSE is:\n",
        "\n",
        "*FILL THE VAULE HERE*\n",
        "\n",
        "Explain what heppends when the value is higher:\n",
        "\n",
        "*YOUR EXPLANATION HERE*\n",
        "\n",
        "Explain what heppends when the value is lower:\n",
        "\n",
        "*YOUR EXPLANATION HERE*\n",
        "\n",
        "(10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miPzzKel9MFf"
      },
      "source": [
        "# Bouns: Implement kNN (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKUUPHyH9MFg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Write your own implementation of KNN. Your code should pass tests in the cell below.\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        \"\"\"\n",
        "        Method is called when an object is created\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Method is called to train (fit) the model\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        return\n",
        "\n",
        "    def predict(self, X_test) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Method is called to predict labels for new data\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        return predictions # predictions should be in format of Numpy array\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxo7UAt09MFi"
      },
      "source": [
        "Run the following cell to test your code.\n",
        "\n",
        "Note: This action is required for grading purposes (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wD54Uv79MFi"
      },
      "outputs": [],
      "source": [
        "def test_knn():\n",
        "    model = KNN(k=3)\n",
        "\n",
        "    # Basic Test\n",
        "    X_train = np.array([[1, 2], [2, 3], [3, 4], [5, 6], [6, 7]])\n",
        "    y_train = np.array([0, 0, 0, 1, 1])\n",
        "    X_test = np.array([[4, 5], [7, 8]])\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    assert np.array_equal(predictions, np.array([0, 1])), f\"Expected [0, 1] but got {predictions}\"\n",
        "\n",
        "    # Edge Case Test: All points are equidistant from test point\n",
        "    X_train = np.array([[1, 1], [1, 1], [1, 1]])\n",
        "    y_train = np.array([0, 1, 2])\n",
        "    X_test = np.array([[1, 1]])\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    assert predictions[0] in y_train, f\"Prediction should be one of the training labels, got {predictions[0]}\"\n",
        "\n",
        "    # Different k-values Test\n",
        "    X_train = np.array([[1, 2], [2, 3], [3, 4], [5, 6], [6, 7]])\n",
        "    y_train = np.array([0, 0, 0, 1, 1])\n",
        "    X_test = np.array([[4, 5]])\n",
        "\n",
        "    model = KNN(k=1)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    assert predictions[0] == 0, f\"Expected 0 but got {predictions[0]}\"\n",
        "\n",
        "    model = KNN(k=5)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    assert predictions[0] == 0, f\"Expected 0 but got {predictions[0]}\"\n",
        "\n",
        "    # Tie Case Test\n",
        "    X_train = np.array([[1, 2], [2, 3], [5, 6], [6, 7]])\n",
        "    y_train = np.array([0, 0, 1, 1])\n",
        "    X_test = np.array([[4, 5]])\n",
        "    model = KNN(k=3)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    assert predictions[0] == 0 or predictions[0] == 1, f\"Expected 0 or 1 but got {predictions[0]}\"\n",
        "\n",
        "    print(\"All tests passed! Your code works as expected\")\n",
        "\n",
        "test_knn()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}